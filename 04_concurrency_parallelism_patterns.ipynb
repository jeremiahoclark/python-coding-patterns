{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeremiahoclark/python-coding-patterns/blob/main/04_concurrency_parallelism_patterns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYE3PxtVQ-ml"
      },
      "source": [
        "# 4. Concurrency and Parallelism Patterns\n",
        "\n",
        "Writing concurrent (multithreaded or async) and parallel (multi-process or multi-core) code in Python can greatly enhance performance for I/O-bound tasks and utilize multiple CPUs for CPU-bound tasks. Python offers several concurrency models: threads, processes, async IO, and more. Here we'll cover patterns such as Producer-Consumer, Thread Pool, futures, and async/await usage.\n",
        "\n",
        "**Note:** Due to the Global Interpreter Lock (GIL) in CPython, threads do not run Python bytecode in true parallel on multiple cores; they are best for I/O-bound tasks. For CPU-bound tasks, multiple processes or releasing the GIL via C extensions (e.g., numpy) is used. We'll see patterns for both scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTsBkO1aQ-mm"
      },
      "source": [
        "## 4.1 Producer-Consumer Pattern (Thread-based)\n",
        "\n",
        "**Pattern Profile:**\n",
        "\n",
        "- **Name:** Producer-Consumer\n",
        "- **Category:** Concurrency Design Pattern\n",
        "- **Difficulty:** Intermediate\n",
        "- **Python Version:** 3.x (uses `queue.Queue`, `threading`)\n",
        "- **Dependencies:** `threading`, `queue` (std lib)\n",
        "\n",
        "**Problem Statement:** When one part of a program produces data and another part consumes it, coordinating them can be challenging. The producer-consumer pattern decouples production and consumption using a thread-safe queue. Producers put items into the queue; consumers take items out. This smooths out differences in production/consumption rates and avoids the producer overwriting data that hasn't been processed.\n",
        "\n",
        "**Solution Approach:** Use a `queue.Queue` (thread-safe, blocking) for communication. Start producer thread(s) that read or generate data and `.put()` into the queue. Start consumer thread(s) that `.get()` from the queue and process data. Use queue blocking operations or a sentinel value to signal completion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9pPXRVIQ-mm"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Create a bounded queue\n",
        "q = queue.Queue(maxsize=5)  # bounded buffer of size 5\n",
        "\n",
        "def producer(name, count):\n",
        "    \"\"\"Producer function that generates items and puts them in the queue\"\"\"\n",
        "    for i in range(count):\n",
        "        item = f\"{name}-item{i}\"\n",
        "        q.put(item)  # will block if queue is full\n",
        "        print(f\"[Producer {name}] produced {item}\")\n",
        "        time.sleep(random.random()*0.1)  # simulate work\n",
        "    q.put(None)  # sentinel for end of production\n",
        "    print(f\"[Producer {name}] done.\")\n",
        "\n",
        "def consumer(name):\n",
        "    \"\"\"Consumer function that processes items from the queue\"\"\"\n",
        "    while True:\n",
        "        item = q.get()  # will block if queue is empty\n",
        "        if item is None:\n",
        "            # put back sentinel for other consumers and exit\n",
        "            q.put(None)\n",
        "            print(f\"(Consumer {name} sees shutdown signal)\")\n",
        "            break\n",
        "        print(f\"--> [Consumer {name}] consuming {item}\")\n",
        "        time.sleep(random.random()*0.2)  # simulate processing\n",
        "        q.task_done()\n",
        "\n",
        "# Example usage - comment out when running other examples\n",
        "if __name__ == \"__main__\":\n",
        "    # Launch one producer and two consumers\n",
        "    producer_thread = threading.Thread(target=producer, args=(\"P1\", 10), daemon=True)\n",
        "    consumer_threads = [threading.Thread(target=consumer, args=(f\"C{i}\",), daemon=True) for i in (1,2)]\n",
        "\n",
        "    producer_thread.start()\n",
        "    for ct in consumer_threads:\n",
        "        ct.start()\n",
        "\n",
        "    producer_thread.join()\n",
        "    q.join()  # wait until all items including sentinel are processed\n",
        "    print(\"All done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYkPUIJpQ-mm"
      },
      "source": [
        "**Advanced Producer-Consumer Example with Multiple Producers:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiJp_XWXQ-mm"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import random\n",
        "\n",
        "class ProducerConsumerDemo:\n",
        "    def __init__(self, queue_size=10):\n",
        "        self.queue = queue.Queue(maxsize=queue_size)\n",
        "        self.active_producers = 0\n",
        "        self.lock = threading.Lock()\n",
        "\n",
        "    def producer(self, name, count):\n",
        "        \"\"\"Enhanced producer with proper shutdown coordination\"\"\"\n",
        "        with self.lock:\n",
        "            self.active_producers += 1\n",
        "\n",
        "        try:\n",
        "            for i in range(count):\n",
        "                item = f\"{name}-item{i}\"\n",
        "                self.queue.put(item)\n",
        "                print(f\"[Producer {name}] produced {item}\")\n",
        "                time.sleep(random.uniform(0.01, 0.1))  # simulate work\n",
        "        finally:\n",
        "            with self.lock:\n",
        "                self.active_producers -= 1\n",
        "                if self.active_producers == 0:\n",
        "                    # Last producer signals end\n",
        "                    self.queue.put(None)\n",
        "                    print(f\"[Producer {name}] is last producer, signaling end\")\n",
        "                else:\n",
        "                    print(f\"[Producer {name}] done, {self.active_producers} producers still active\")\n",
        "\n",
        "    def consumer(self, name):\n",
        "        \"\"\"Enhanced consumer with graceful shutdown\"\"\"\n",
        "        processed = 0\n",
        "        while True:\n",
        "            try:\n",
        "                item = self.queue.get(timeout=1)  # timeout to avoid infinite wait\n",
        "                if item is None:\n",
        "                    print(f\"(Consumer {name}) received shutdown signal after processing {processed} items\")\n",
        "                    self.queue.put(None)  # pass signal to other consumers\n",
        "                    break\n",
        "\n",
        "                print(f\"--> [Consumer {name}] consuming {item}\")\n",
        "                time.sleep(random.uniform(0.05, 0.15))  # simulate processing\n",
        "                processed += 1\n",
        "                self.queue.task_done()\n",
        "\n",
        "            except queue.Empty:\n",
        "                print(f\"(Consumer {name}) timed out waiting for items\")\n",
        "                continue\n",
        "\n",
        "    def run_demo(self, num_producers=3, num_consumers=2, items_per_producer=5):\n",
        "        \"\"\"Run the producer-consumer demo\"\"\"\n",
        "        print(f\"Starting demo with {num_producers} producers, {num_consumers} consumers\")\n",
        "\n",
        "        # Create and start producer threads\n",
        "        producer_threads = []\n",
        "        for i in range(num_producers):\n",
        "            thread = threading.Thread(target=self.producer, args=(f\"P{i+1}\", items_per_producer))\n",
        "            producer_threads.append(thread)\n",
        "            thread.start()\n",
        "\n",
        "        # Create and start consumer threads\n",
        "        consumer_threads = []\n",
        "        for i in range(num_consumers):\n",
        "            thread = threading.Thread(target=self.consumer, args=(f\"C{i+1}\",))\n",
        "            consumer_threads.append(thread)\n",
        "            thread.start()\n",
        "\n",
        "        # Wait for all producers to finish\n",
        "        for thread in producer_threads:\n",
        "            thread.join()\n",
        "\n",
        "        # Wait for all consumers to finish\n",
        "        for thread in consumer_threads:\n",
        "            thread.join()\n",
        "\n",
        "        print(\"Demo completed!\")\n",
        "\n",
        "# Run the demo\n",
        "demo = ProducerConsumerDemo()\n",
        "demo.run_demo(num_producers=2, num_consumers=3, items_per_producer=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyKHmNMkQ-mn"
      },
      "source": [
        "## 4.2 Thread Pool and Futures\n",
        "\n",
        "**Pattern Profile:**\n",
        "\n",
        "- **Name:** ThreadPoolExecutor (Thread Pool Pattern)\n",
        "- **Category:** Concurrency Pattern\n",
        "- **Difficulty:** Beginner\n",
        "- **Python Version:** 3.2+ (`concurrent.futures`)\n",
        "- **Dependencies:** `concurrent.futures.ThreadPoolExecutor`\n",
        "\n",
        "**Problem Statement:** Creating and destroying threads for many short tasks is expensive. A thread pool reuses a fixed number of threads to execute many tasks. In Python, the `concurrent.futures.ThreadPoolExecutor` provides a high-level interface to submit callables (tasks) to a pool of threads and get back a **Future** object representing the pending result. This pattern is useful for parallelizing I/O-bound operations easily.\n",
        "\n",
        "**Solution Approach:** Use `ThreadPoolExecutor` with a certain `max_workers`. Submit tasks (callable + arguments) using `executor.submit(fn, *args)`, which returns a Future. A Future can be used to check status or retrieve the result (with `.result()` blocking until done or `.add_done_callback`). Alternatively, use `executor.map(fn, iterable)` to map a function over an iterable in multiple threads, returning results as they come."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqFKoL8cQ-mn"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
        "import time\n",
        "import random\n",
        "import requests  # Note: you may need to install requests\n",
        "\n",
        "# Simulated I/O-bound task\n",
        "def simulate_io_task(task_id, duration):\n",
        "    \"\"\"Simulate an I/O-bound task like reading a file or making a network request\"\"\"\n",
        "    print(f\"Task {task_id} starting (will take {duration:.2f}s)\")\n",
        "    time.sleep(duration)  # Simulate I/O wait\n",
        "    result = f\"Task {task_id} completed after {duration:.2f}s\"\n",
        "    print(f\"Task {task_id} finished\")\n",
        "    return result\n",
        "\n",
        "# Example 1: Using submit() and as_completed()\n",
        "def thread_pool_submit_example():\n",
        "    print(\"=== ThreadPool with submit() example ===\")\n",
        "    tasks = [(i, random.uniform(0.5, 2.0)) for i in range(5)]\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "        # Submit all tasks\n",
        "        futures = {executor.submit(simulate_io_task, task_id, duration): task_id\n",
        "                  for task_id, duration in tasks}\n",
        "\n",
        "        # Process results as they complete\n",
        "        for future in as_completed(futures):\n",
        "            task_id = futures[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "                print(f\"Got result: {result}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Task {task_id} generated an exception: {e}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Total time: {end_time - start_time:.2f}s\\n\")\n",
        "\n",
        "thread_pool_submit_example()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NshZ7r-PQ-mn"
      },
      "outputs": [],
      "source": [
        "# Example 2: Using map() for simpler cases\n",
        "def thread_pool_map_example():\n",
        "    print(\"=== ThreadPool with map() example ===\")\n",
        "\n",
        "    def process_item(item):\n",
        "        \"\"\"Process a single item\"\"\"\n",
        "        time.sleep(random.uniform(0.1, 0.5))\n",
        "        return f\"Processed {item} -> {item.upper()}\"\n",
        "\n",
        "    items = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\"]\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "        # map() returns results in the same order as input\n",
        "        results = list(executor.map(process_item, items))\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    for result in results:\n",
        "        print(result)\n",
        "\n",
        "    print(f\"Total time: {end_time - start_time:.2f}s\\n\")\n",
        "\n",
        "thread_pool_map_example()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg5gYBmxQ-mn"
      },
      "outputs": [],
      "source": [
        "# Example 3: CPU-bound task with ProcessPoolExecutor\n",
        "def cpu_intensive_task(n):\n",
        "    \"\"\"A CPU-intensive task - calculating prime numbers\"\"\"\n",
        "    def is_prime(num):\n",
        "        if num < 2:\n",
        "            return False\n",
        "        for i in range(2, int(num ** 0.5) + 1):\n",
        "            if num % i == 0:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    # Find prime numbers up to n\n",
        "    primes = [i for i in range(2, n) if is_prime(i)]\n",
        "    return len(primes)\n",
        "\n",
        "def compare_thread_vs_process():\n",
        "    print(\"=== Comparing ThreadPool vs ProcessPool for CPU-bound tasks ===\")\n",
        "\n",
        "    numbers = [10000, 15000, 20000, 25000]\n",
        "\n",
        "    # Using ThreadPoolExecutor (limited by GIL for CPU-bound)\n",
        "    print(\"Using ThreadPoolExecutor:\")\n",
        "    start_time = time.time()\n",
        "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        thread_results = list(executor.map(cpu_intensive_task, numbers))\n",
        "    thread_time = time.time() - start_time\n",
        "    print(f\"Results: {thread_results}\")\n",
        "    print(f\"Thread time: {thread_time:.2f}s\")\n",
        "\n",
        "    # Using ProcessPoolExecutor (can utilize multiple cores)\n",
        "    print(\"\\nUsing ProcessPoolExecutor:\")\n",
        "    start_time = time.time()\n",
        "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
        "        process_results = list(executor.map(cpu_intensive_task, numbers))\n",
        "    process_time = time.time() - start_time\n",
        "    print(f\"Results: {process_results}\")\n",
        "    print(f\"Process time: {process_time:.2f}s\")\n",
        "\n",
        "    print(f\"\\nSpeedup with processes: {thread_time / process_time:.2f}x\")\n",
        "\n",
        "compare_thread_vs_process()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElotKQTCQ-mn"
      },
      "source": [
        "**Advanced Futures Example with Callbacks:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azeGRAtDQ-mn"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "import random\n",
        "\n",
        "def task_with_callback_demo():\n",
        "    print(\"=== Futures with Callbacks Example ===\")\n",
        "\n",
        "    def long_running_task(task_id):\n",
        "        \"\"\"A task that might succeed or fail\"\"\"\n",
        "        duration = random.uniform(1, 3)\n",
        "        time.sleep(duration)\n",
        "\n",
        "        # Randomly fail some tasks\n",
        "        if random.random() < 0.3:\n",
        "            raise Exception(f\"Task {task_id} failed randomly\")\n",
        "\n",
        "        return f\"Task {task_id} succeeded after {duration:.2f}s\"\n",
        "\n",
        "    def success_callback(future):\n",
        "        \"\"\"Called when a task completes successfully\"\"\"\n",
        "        try:\n",
        "            result = future.result()\n",
        "            print(f\"✅ SUCCESS: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ FAILED: {e}\")\n",
        "\n",
        "    # Submit tasks with callbacks\n",
        "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
        "        futures = []\n",
        "\n",
        "        for i in range(5):\n",
        "            future = executor.submit(long_running_task, i)\n",
        "            future.add_done_callback(success_callback)\n",
        "            futures.append(future)\n",
        "\n",
        "        # Wait for all to complete\n",
        "        for future in futures:\n",
        "            try:\n",
        "                future.result()  # This will re-raise any exceptions\n",
        "            except Exception:\n",
        "                pass  # Already handled by callback\n",
        "\n",
        "    print(\"All tasks completed!\")\n",
        "\n",
        "task_with_callback_demo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfJtiP8lQ-mo"
      },
      "source": [
        "## 4.3 Async/Await and Event Loop Pattern\n",
        "\n",
        "**Pattern Profile:**\n",
        "\n",
        "- **Name:** Asyncio Event Loop (async/await)\n",
        "- **Category:** Concurrency (asynchronous I/O pattern)\n",
        "- **Difficulty:** Advanced\n",
        "- **Python Version:** 3.5+ (async/await syntax)\n",
        "- **Dependencies:** `asyncio`\n",
        "\n",
        "**Problem Statement:** Traditional threading can have overhead and isn't ideal for high-number-of-connection I/O tasks (e.g., thousands of sockets). Async IO uses an event loop (single-threaded) that cooperatively multitasks across awaiting tasks, suitable for many concurrent I/O operations without the overhead of threads. The pattern is essentially an implementation of the **Reactor pattern** (event loop that waits for events and dispatches handlers) combined with language support via `async/await` to make it easier to write sequential-looking code.\n",
        "\n",
        "**Solution Approach:** Use `asyncio` library:\n",
        "\n",
        "- Define `async def` coroutines that use `await` to yield control when performing I/O\n",
        "- Get an event loop (automatically with `asyncio.run(main())` in Python 3.7+ or manually)\n",
        "- Schedule tasks with `asyncio.create_task(coro)` if needed to run concurrently within an async function\n",
        "- The event loop will run, awaiting I/O completion and switching between tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDEGUKcXQ-mo"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Basic async producer-consumer example\n",
        "async def async_producer(queue: asyncio.Queue, count: int):\n",
        "    \"\"\"Async producer that generates items\"\"\"\n",
        "    for i in range(count):\n",
        "        await asyncio.sleep(random.random()*0.1)  # simulate async work\n",
        "        item = f\"item{i}\"\n",
        "        await queue.put(item)\n",
        "        print(f\"[Async Producer] produced {item}\")\n",
        "    await queue.put(None)  # sentinel\n",
        "    print(\"[Async Producer] done producing.\")\n",
        "\n",
        "async def async_consumer(queue: asyncio.Queue, name: str):\n",
        "    \"\"\"Async consumer that processes items\"\"\"\n",
        "    while True:\n",
        "        item = await queue.get()\n",
        "        if item is None:\n",
        "            await queue.put(None)  # pass sentinel along for other consumers\n",
        "            print(f\"(Async Consumer {name}) sees shutdown signal\")\n",
        "            break\n",
        "        print(f\"--> (Async Consumer {name}) consuming {item}\")\n",
        "        await asyncio.sleep(random.random()*0.2)  # simulate async processing\n",
        "\n",
        "async def async_producer_consumer_demo():\n",
        "    \"\"\"Demo of async producer-consumer pattern\"\"\"\n",
        "    print(\"=== Async Producer-Consumer Demo ===\")\n",
        "\n",
        "    queue = asyncio.Queue(maxsize=5)\n",
        "\n",
        "    # Schedule one producer and two consumers concurrently\n",
        "    prod_task = asyncio.create_task(async_producer(queue, 10))\n",
        "    cons_tasks = [asyncio.create_task(async_consumer(queue, f\"C{i}\")) for i in (1,2)]\n",
        "\n",
        "    # Wait for producer to finish\n",
        "    await prod_task\n",
        "\n",
        "    # Wait for consumers to finish\n",
        "    await asyncio.gather(*cons_tasks)\n",
        "\n",
        "    print(\"Async demo completed!\")\n",
        "\n",
        "# Run the async demo\n",
        "asyncio.run(async_producer_consumer_demo())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwdWqey_Q-mo"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import aiohttp  # Note: you may need to install aiohttp\n",
        "import time\n",
        "\n",
        "# Async HTTP client example\n",
        "async def fetch_url(session, url):\n",
        "    \"\"\"Fetch a single URL asynchronously\"\"\"\n",
        "    try:\n",
        "        async with session.get(url) as response:\n",
        "            content = await response.text()\n",
        "            return url, response.status, len(content)\n",
        "    except Exception as e:\n",
        "        return url, \"ERROR\", str(e)\n",
        "\n",
        "async def async_http_demo():\n",
        "    \"\"\"Demo of concurrent HTTP requests using async\"\"\"\n",
        "    print(\"=== Async HTTP Requests Demo ===\")\n",
        "\n",
        "    # Test URLs (using httpbin for reliable testing)\n",
        "    urls = [\n",
        "        \"https://httpbin.org/delay/1\",\n",
        "        \"https://httpbin.org/delay/2\",\n",
        "        \"https://httpbin.org/delay/1\",\n",
        "        \"https://httpbin.org/status/200\",\n",
        "        \"https://httpbin.org/json\"\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        # Start all requests concurrently\n",
        "        tasks = [fetch_url(session, url) for url in urls]\n",
        "        results = await asyncio.gather(*tasks)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    for url, status, content_info in results:\n",
        "        print(f\"{url} -> Status: {status}, Content: {content_info}\")\n",
        "\n",
        "    print(f\"Total time: {end_time - start_time:.2f}s\")\n",
        "    print(\"Note: This would take ~6s sequentially, but much less concurrently!\")\n",
        "\n",
        "# Uncomment to run (requires aiohttp installation)\n",
        "# asyncio.run(async_http_demo())\n",
        "\n",
        "print(\"HTTP demo code ready (install aiohttp to run)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPv51GIFQ-mo"
      },
      "outputs": [],
      "source": [
        "# Advanced async patterns: semaphores, locks, and error handling\n",
        "import asyncio\n",
        "import random\n",
        "\n",
        "async def limited_resource_demo():\n",
        "    \"\"\"Demo using semaphores to limit concurrent resource access\"\"\"\n",
        "    print(\"=== Async Semaphore Demo ===\")\n",
        "\n",
        "    # Limit to 2 concurrent \"connections\"\n",
        "    semaphore = asyncio.Semaphore(2)\n",
        "\n",
        "    async def access_limited_resource(resource_id):\n",
        "        async with semaphore:  # Acquire semaphore\n",
        "            print(f\"Resource {resource_id} acquired semaphore\")\n",
        "            await asyncio.sleep(random.uniform(1, 3))  # Simulate work\n",
        "            print(f\"Resource {resource_id} releasing semaphore\")\n",
        "            return f\"Resource {resource_id} completed\"\n",
        "\n",
        "    # Start 5 tasks, but only 2 can run concurrently\n",
        "    tasks = [access_limited_resource(i) for i in range(5)]\n",
        "    results = await asyncio.gather(*tasks)\n",
        "\n",
        "    for result in results:\n",
        "        print(f\"✅ {result}\")\n",
        "\n",
        "async def async_lock_demo():\n",
        "    \"\"\"Demo using async locks for shared state\"\"\"\n",
        "    print(\"\\n=== Async Lock Demo ===\")\n",
        "\n",
        "    shared_counter = 0\n",
        "    lock = asyncio.Lock()\n",
        "\n",
        "    async def increment_counter(worker_id, increments):\n",
        "        nonlocal shared_counter\n",
        "\n",
        "        for i in range(increments):\n",
        "            async with lock:  # Critical section\n",
        "                current = shared_counter\n",
        "                await asyncio.sleep(0.01)  # Simulate work that could cause race condition\n",
        "                shared_counter = current + 1\n",
        "                print(f\"Worker {worker_id}: counter = {shared_counter}\")\n",
        "\n",
        "    # Start multiple workers\n",
        "    tasks = [increment_counter(i, 3) for i in range(3)]\n",
        "    await asyncio.gather(*tasks)\n",
        "\n",
        "    print(f\"Final counter value: {shared_counter}\")\n",
        "\n",
        "async def error_handling_demo():\n",
        "    \"\"\"Demo proper error handling in async code\"\"\"\n",
        "    print(\"\\n=== Async Error Handling Demo ===\")\n",
        "\n",
        "    async def task_that_might_fail(task_id):\n",
        "        await asyncio.sleep(random.uniform(0.1, 0.5))\n",
        "        if random.random() < 0.4:  # 40% chance of failure\n",
        "            raise ValueError(f\"Task {task_id} failed!\")\n",
        "        return f\"Task {task_id} succeeded\"\n",
        "\n",
        "    tasks = [task_that_might_fail(i) for i in range(5)]\n",
        "\n",
        "    # Method 1: Catch all exceptions with return_exceptions=True\n",
        "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    for i, result in enumerate(results):\n",
        "        if isinstance(result, Exception):\n",
        "            print(f\"❌ Task {i}: {result}\")\n",
        "        else:\n",
        "            print(f\"✅ Task {i}: {result}\")\n",
        "\n",
        "# Run all demos\n",
        "async def main_async_demos():\n",
        "    await limited_resource_demo()\n",
        "    await async_lock_demo()\n",
        "    await error_handling_demo()\n",
        "\n",
        "asyncio.run(main_async_demos())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV0UbB8KQ-mo"
      },
      "source": [
        "## Performance Comparison: Threads vs Async vs Processes\n",
        "\n",
        "Let's compare the different concurrency approaches for different types of tasks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i__SjfpUQ-mo"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "\n",
        "def io_bound_task(duration):\n",
        "    \"\"\"Simulate I/O-bound work\"\"\"\n",
        "    time.sleep(duration)\n",
        "    return f\"I/O task completed in {duration}s\"\n",
        "\n",
        "async def async_io_task(duration):\n",
        "    \"\"\"Async version of I/O-bound work\"\"\"\n",
        "    await asyncio.sleep(duration)\n",
        "    return f\"Async I/O task completed in {duration}s\"\n",
        "\n",
        "def cpu_bound_task(n):\n",
        "    \"\"\"Simulate CPU-bound work\"\"\"\n",
        "    total = sum(i * i for i in range(n))\n",
        "    return f\"CPU task calculated sum: {total}\"\n",
        "\n",
        "def compare_approaches():\n",
        "    \"\"\"Compare different concurrency approaches\"\"\"\n",
        "    print(\"=== Performance Comparison ===\")\n",
        "\n",
        "    # Test parameters\n",
        "    io_durations = [0.5, 0.8, 0.3, 0.6, 0.4]  # I/O tasks\n",
        "    cpu_values = [100000, 150000, 120000, 180000]  # CPU tasks\n",
        "\n",
        "    # 1. Sequential (baseline)\n",
        "    print(\"\\n1. Sequential I/O:\")\n",
        "    start = time.time()\n",
        "    for duration in io_durations:\n",
        "        io_bound_task(duration)\n",
        "    sequential_time = time.time() - start\n",
        "    print(f\"Time: {sequential_time:.2f}s\")\n",
        "\n",
        "    # 2. ThreadPool for I/O\n",
        "    print(\"\\n2. ThreadPool I/O:\")\n",
        "    start = time.time()\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        results = list(executor.map(io_bound_task, io_durations))\n",
        "    thread_time = time.time() - start\n",
        "    print(f\"Time: {thread_time:.2f}s\")\n",
        "    print(f\"Speedup: {sequential_time / thread_time:.2f}x\")\n",
        "\n",
        "    # 3. Async for I/O\n",
        "    print(\"\\n3. Async I/O:\")\n",
        "    async def async_test():\n",
        "        start = time.time()\n",
        "        tasks = [async_io_task(duration) for duration in io_durations]\n",
        "        await asyncio.gather(*tasks)\n",
        "        return time.time() - start\n",
        "\n",
        "    async_time = asyncio.run(async_test())\n",
        "    print(f\"Time: {async_time:.2f}s\")\n",
        "    print(f\"Speedup: {sequential_time / async_time:.2f}x\")\n",
        "\n",
        "    # 4. CPU-bound comparison\n",
        "    print(\"\\n4. CPU-bound tasks:\")\n",
        "\n",
        "    # Sequential CPU\n",
        "    start = time.time()\n",
        "    for val in cpu_values:\n",
        "        cpu_bound_task(val)\n",
        "    cpu_sequential = time.time() - start\n",
        "    print(f\"Sequential CPU: {cpu_sequential:.2f}s\")\n",
        "\n",
        "    # ThreadPool CPU (limited by GIL)\n",
        "    start = time.time()\n",
        "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        list(executor.map(cpu_bound_task, cpu_values))\n",
        "    cpu_thread = time.time() - start\n",
        "    print(f\"ThreadPool CPU: {cpu_thread:.2f}s (GIL limited)\")\n",
        "\n",
        "    # ProcessPool CPU (can use multiple cores)\n",
        "    start = time.time()\n",
        "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
        "        list(executor.map(cpu_bound_task, cpu_values))\n",
        "    cpu_process = time.time() - start\n",
        "    print(f\"ProcessPool CPU: {cpu_process:.2f}s\")\n",
        "    print(f\"Process speedup: {cpu_sequential / cpu_process:.2f}x\")\n",
        "\n",
        "compare_approaches()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSGt0RnLQ-mo"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Concurrency and parallelism patterns in Python provide powerful tools for improving performance:\n",
        "\n",
        "### Key Patterns Covered:\n",
        "\n",
        "1. **Producer-Consumer Pattern**: Decouples data production and consumption using thread-safe queues\n",
        "2. **Thread Pool Pattern**: Reuses threads for multiple tasks, ideal for I/O-bound operations\n",
        "3. **Async/Await Pattern**: Single-threaded cooperative multitasking for high-concurrency I/O\n",
        "\n",
        "### When to Use What:\n",
        "\n",
        "- **Threading (`ThreadPoolExecutor`)**:\n",
        "  - ✅ I/O-bound tasks (file operations, network requests)\n",
        "  - ❌ CPU-bound tasks (limited by GIL)\n",
        "  - Simple to use, good for moderate concurrency\n",
        "\n",
        "- **Async/Await (`asyncio`)**:\n",
        "  - ✅ High-concurrency I/O (thousands of connections)\n",
        "  - ✅ Single-threaded, no race conditions\n",
        "  - ❌ Requires async ecosystem (aiohttp, asyncpg, etc.)\n",
        "  - Steeper learning curve but very efficient\n",
        "\n",
        "- **Multiprocessing (`ProcessPoolExecutor`)**:\n",
        "  - ✅ CPU-bound tasks (mathematical computations)\n",
        "  - ✅ True parallelism (bypasses GIL)\n",
        "  - ❌ Higher memory overhead\n",
        "  - ❌ Data serialization costs between processes\n",
        "\n",
        "### Best Practices:\n",
        "\n",
        "- Use context managers (`with` statements) for proper resource cleanup\n",
        "- Handle exceptions properly in concurrent code\n",
        "- Use semaphores and locks to control resource access\n",
        "- Consider the nature of your tasks (I/O vs CPU-bound) when choosing approach\n",
        "- Profile and measure - concurrency doesn't always improve performance"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}