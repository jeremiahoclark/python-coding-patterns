{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeremiahoclark/python-coding-patterns/blob/main/08_error_handling_logging_patterns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSvcWimkFHGP"
      },
      "source": [
        "# Error Handling and Logging Patterns\n",
        "\n",
        "This notebook covers essential patterns for robust error handling and effective logging in Python applications, including custom exceptions, graceful error recovery, and structured logging practices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sdSS_-yFHGQ"
      },
      "source": [
        "## 1. Exception Handling Strategies\n",
        "\n",
        "Effective exception handling involves knowing when to catch, when to propagate, and how to use custom exceptions for clear error communication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P031URs9FHGR"
      },
      "outputs": [],
      "source": [
        "# Custom Exception Hierarchy\n",
        "import math\n",
        "import logging\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Base custom exception\n",
        "class ApplicationError(Exception):\n",
        "    \"\"\"Base exception for application-specific errors\"\"\"\n",
        "    def __init__(self, message: str, error_code: str = None, context: Dict[str, Any] = None):\n",
        "        super().__init__(message)\n",
        "        self.message = message\n",
        "        self.error_code = error_code\n",
        "        self.context = context or {}\n",
        "        self.timestamp = datetime.now()\n",
        "\n",
        "# Specific exception types\n",
        "class ValidationError(ApplicationError):\n",
        "    \"\"\"Raised when input validation fails\"\"\"\n",
        "    def __init__(self, message: str, field_errors: Dict[str, str] = None):\n",
        "        super().__init__(message, \"VALIDATION_ERROR\", {\"field_errors\": field_errors or {}})\n",
        "        self.field_errors = field_errors or {}\n",
        "\n",
        "class BusinessLogicError(ApplicationError):\n",
        "    \"\"\"Raised when business rules are violated\"\"\"\n",
        "    def __init__(self, message: str, rule: str = None):\n",
        "        super().__init__(message, \"BUSINESS_LOGIC_ERROR\", {\"rule\": rule})\n",
        "        self.rule = rule\n",
        "\n",
        "class ResourceNotFoundError(ApplicationError):\n",
        "    \"\"\"Raised when a requested resource is not found\"\"\"\n",
        "    def __init__(self, resource_type: str, identifier: Any):\n",
        "        message = f\"{resource_type} not found: {identifier}\"\n",
        "        super().__init__(message, \"RESOURCE_NOT_FOUND\", {\n",
        "            \"resource_type\": resource_type,\n",
        "            \"identifier\": identifier\n",
        "        })\n",
        "        self.resource_type = resource_type\n",
        "        self.identifier = identifier\n",
        "\n",
        "class ExternalServiceError(ApplicationError):\n",
        "    \"\"\"Raised when external service communication fails\"\"\"\n",
        "    def __init__(self, service_name: str, operation: str, cause: Exception = None):\n",
        "        message = f\"External service error in {service_name}.{operation}\"\n",
        "        super().__init__(message, \"EXTERNAL_SERVICE_ERROR\", {\n",
        "            \"service_name\": service_name,\n",
        "            \"operation\": operation\n",
        "        })\n",
        "        self.service_name = service_name\n",
        "        self.operation = operation\n",
        "        self.cause = cause\n",
        "\n",
        "class ConfigurationError(ApplicationError):\n",
        "    \"\"\"Raised when configuration is invalid or missing\"\"\"\n",
        "    def __init__(self, config_key: str, expected: str = None):\n",
        "        message = f\"Invalid configuration: {config_key}\"\n",
        "        if expected:\n",
        "            message += f\" (expected: {expected})\"\n",
        "        super().__init__(message, \"CONFIGURATION_ERROR\", {\n",
        "            \"config_key\": config_key,\n",
        "            \"expected\": expected\n",
        "        })\n",
        "\n",
        "print(\"Custom exception hierarchy defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjN7DLCjFHGR"
      },
      "outputs": [],
      "source": [
        "# Exception Handling Patterns and Strategies\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from functools import wraps\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# Pattern 1: EAFP (Easier to Ask for Forgiveness than Permission)\n",
        "class Calculator:\n",
        "    \"\"\"Calculator demonstrating EAFP and custom exceptions\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def safe_divide(numerator: float, denominator: float) -> float:\n",
        "        \"\"\"Divide two numbers with custom exception for zero division\"\"\"\n",
        "        if denominator == 0:\n",
        "            raise BusinessLogicError(\n",
        "                \"Division by zero is not allowed\",\n",
        "                rule=\"non_zero_denominator\"\n",
        "            )\n",
        "        return numerator / denominator\n",
        "\n",
        "    @staticmethod\n",
        "    def safe_sqrt(number: float) -> float:\n",
        "        \"\"\"Calculate square root with validation\"\"\"\n",
        "        if number < 0:\n",
        "            raise ValidationError(\n",
        "                \"Cannot calculate square root of negative number\",\n",
        "                field_errors={\"number\": \"Must be non-negative\"}\n",
        "            )\n",
        "        return math.sqrt(number)\n",
        "\n",
        "    @staticmethod\n",
        "    def safe_log(number: float, base: float = math.e) -> float:\n",
        "        \"\"\"Calculate logarithm with validation\"\"\"\n",
        "        errors = {}\n",
        "        if number <= 0:\n",
        "            errors[\"number\"] = \"Must be positive\"\n",
        "        if base <= 0 or base == 1:\n",
        "            errors[\"base\"] = \"Must be positive and not equal to 1\"\n",
        "\n",
        "        if errors:\n",
        "            raise ValidationError(\"Invalid logarithm parameters\", field_errors=errors)\n",
        "\n",
        "        return math.log(number, base)\n",
        "\n",
        "# Pattern 2: Retry with exponential backoff\n",
        "def retry_with_backoff(max_attempts: int = 3, base_delay: float = 1.0,\n",
        "                      backoff_factor: float = 2.0, exceptions: tuple = None):\n",
        "    \"\"\"Decorator for retrying operations with exponential backoff\"\"\"\n",
        "    if exceptions is None:\n",
        "        exceptions = (ExternalServiceError,)\n",
        "\n",
        "    def decorator(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            last_exception = None\n",
        "\n",
        "            for attempt in range(max_attempts):\n",
        "                try:\n",
        "                    return func(*args, **kwargs)\n",
        "                except exceptions as e:\n",
        "                    last_exception = e\n",
        "                    if attempt == max_attempts - 1:\n",
        "                        # Last attempt, re-raise\n",
        "                        raise\n",
        "\n",
        "                    delay = base_delay * (backoff_factor ** attempt)\n",
        "                    print(f\"Attempt {attempt + 1} failed: {e}. Retrying in {delay:.1f}s...\")\n",
        "                    time.sleep(delay)\n",
        "\n",
        "            # This should never be reached, but just in case\n",
        "            raise last_exception\n",
        "\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Pattern 3: Context manager for resource cleanup\n",
        "@contextmanager\n",
        "def temporary_config(config_changes: Dict[str, Any]):\n",
        "    \"\"\"Context manager for temporary configuration changes\"\"\"\n",
        "    original_values = {}\n",
        "\n",
        "    # Save original values and apply changes\n",
        "    for key, new_value in config_changes.items():\n",
        "        original_values[key] = os.environ.get(key)\n",
        "        os.environ[key] = str(new_value)\n",
        "\n",
        "    try:\n",
        "        yield\n",
        "    except Exception as e:\n",
        "        print(f\"Exception occurred during temporary config: {e}\")\n",
        "        raise\n",
        "    finally:\n",
        "        # Restore original values\n",
        "        for key, original_value in original_values.items():\n",
        "            if original_value is None:\n",
        "                os.environ.pop(key, None)\n",
        "            else:\n",
        "                os.environ[key] = original_value\n",
        "\n",
        "# Pattern 4: Exception chaining\n",
        "class DataProcessor:\n",
        "    \"\"\"Demonstrates exception chaining and context preservation\"\"\"\n",
        "\n",
        "    def parse_number(self, value: str) -> float:\n",
        "        \"\"\"Parse string to number with context preservation\"\"\"\n",
        "        try:\n",
        "            return float(value)\n",
        "        except ValueError as e:\n",
        "            raise ValidationError(\n",
        "                f\"Invalid number format: '{value}'\",\n",
        "                field_errors={\"value\": \"Must be a valid number\"}\n",
        "            ) from e\n",
        "\n",
        "    def load_config_file(self, filename: str) -> Dict[str, Any]:\n",
        "        \"\"\"Load configuration from file with proper error handling\"\"\"\n",
        "        try:\n",
        "            with open(filename, 'r') as f:\n",
        "                data = json.load(f)\n",
        "                return data\n",
        "        except FileNotFoundError as e:\n",
        "            raise ConfigurationError(f\"config_file:{filename}\", \"existing file\") from e\n",
        "        except json.JSONDecodeError as e:\n",
        "            raise ConfigurationError(\n",
        "                f\"config_file:{filename}\",\n",
        "                \"valid JSON format\"\n",
        "            ) from e\n",
        "        except PermissionError as e:\n",
        "            raise ConfigurationError(\n",
        "                f\"config_file_permissions:{filename}\",\n",
        "                \"read permissions\"\n",
        "            ) from e\n",
        "\n",
        "print(\"Exception handling patterns defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irrg28fPFHGS"
      },
      "outputs": [],
      "source": [
        "# Demonstrate exception handling patterns\n",
        "print(\"=== Exception Handling Patterns Demo ===\")\n",
        "\n",
        "calculator = Calculator()\n",
        "processor = DataProcessor()\n",
        "\n",
        "# Test 1: Basic custom exceptions\n",
        "print(\"\\n1. Testing custom exceptions:\")\n",
        "test_cases = [\n",
        "    (\"safe_divide\", [10, 2]),\n",
        "    (\"safe_divide\", [10, 0]),  # Should raise BusinessLogicError\n",
        "    (\"safe_sqrt\", [16]),\n",
        "    (\"safe_sqrt\", [-4]),  # Should raise ValidationError\n",
        "    (\"safe_log\", [100, 10]),\n",
        "    (\"safe_log\", [-5, 10]),  # Should raise ValidationError\n",
        "]\n",
        "\n",
        "for method_name, args in test_cases:\n",
        "    try:\n",
        "        method = getattr(calculator, method_name)\n",
        "        result = method(*args)\n",
        "        print(f\"  {method_name}({', '.join(map(str, args))}) = {result}\")\n",
        "    except ApplicationError as e:\n",
        "        print(f\"  {method_name}({', '.join(map(str, args))}) -> {type(e).__name__}: {e.message}\")\n",
        "        if hasattr(e, 'field_errors') and e.field_errors:\n",
        "            print(f\"    Field errors: {e.field_errors}\")\n",
        "\n",
        "# Test 2: Exception chaining\n",
        "print(\"\\n2. Testing exception chaining:\")\n",
        "try:\n",
        "    number = processor.parse_number(\"not_a_number\")\n",
        "except ValidationError as e:\n",
        "    print(f\"Caught: {type(e).__name__}: {e.message}\")\n",
        "    print(f\"Original cause: {type(e.__cause__).__name__}: {e.__cause__}\")\n",
        "\n",
        "# Test 3: Context manager for cleanup\n",
        "print(\"\\n3. Testing context manager:\")\n",
        "print(f\"Original PATH length: {len(os.environ.get('PATH', ''))}\")\n",
        "\n",
        "try:\n",
        "    with temporary_config({\"TEST_VAR\": \"temporary_value\", \"PATH\": \"/tmp\"}):\n",
        "        print(f\"Temporary PATH: {os.environ.get('PATH')}\")\n",
        "        print(f\"TEST_VAR: {os.environ.get('TEST_VAR')}\")\n",
        "        # Simulate an error\n",
        "        raise ValueError(\"Simulated error\")\n",
        "except ValueError as e:\n",
        "    print(f\"Caught error: {e}\")\n",
        "\n",
        "print(f\"Restored PATH length: {len(os.environ.get('PATH', ''))}\")\n",
        "print(f\"TEST_VAR after cleanup: {os.environ.get('TEST_VAR', 'Not set')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlK4wguTFHGS"
      },
      "outputs": [],
      "source": [
        "# Demonstrate retry pattern\n",
        "print(\"\\n4. Testing retry pattern:\")\n",
        "\n",
        "class UnreliableService:\n",
        "    \"\"\"Simulates an unreliable external service\"\"\"\n",
        "\n",
        "    def __init__(self, failure_rate: float = 0.7):\n",
        "        self.failure_rate = failure_rate\n",
        "        self.attempt_count = 0\n",
        "\n",
        "    @retry_with_backoff(max_attempts=3, base_delay=0.1, exceptions=(ExternalServiceError,))\n",
        "    def unreliable_operation(self, data: str) -> str:\n",
        "        \"\"\"Operation that fails randomly\"\"\"\n",
        "        self.attempt_count += 1\n",
        "        print(f\"    Attempting operation (attempt {self.attempt_count})...\")\n",
        "\n",
        "        if random.random() < self.failure_rate:\n",
        "            raise ExternalServiceError(\"payment_service\", \"process_payment\",\n",
        "                                     cause=Exception(\"Network timeout\"))\n",
        "\n",
        "        return f\"Success: Processed '{data}'\"\n",
        "\n",
        "    def reset(self):\n",
        "        self.attempt_count = 0\n",
        "\n",
        "# Test retry with different failure rates\n",
        "service = UnreliableService(failure_rate=0.6)  # 60% failure rate\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"\\nTest {i+1}:\")\n",
        "    service.reset()\n",
        "    try:\n",
        "        result = service.unreliable_operation(f\"test_data_{i}\")\n",
        "        print(f\"  Result: {result}\")\n",
        "    except ExternalServiceError as e:\n",
        "        print(f\"  Final failure: {e.message}\")\n",
        "    print(f\"  Total attempts made: {service.attempt_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INis5zTuFHGS"
      },
      "outputs": [],
      "source": [
        "# Advanced error handling patterns\n",
        "from contextlib import suppress\n",
        "from typing import Type, Callable, Any\n",
        "\n",
        "# Pattern 5: Graceful degradation\n",
        "class FeatureManager:\n",
        "    \"\"\"Manages optional features with graceful degradation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.features = {\n",
        "            'analytics': True,\n",
        "            'caching': True,\n",
        "            'notifications': True\n",
        "        }\n",
        "\n",
        "    def safe_feature_call(self, feature_name: str, operation: Callable,\n",
        "                         fallback: Any = None, critical: bool = False):\n",
        "        \"\"\"Execute feature operation with graceful degradation\"\"\"\n",
        "        if not self.features.get(feature_name, False):\n",
        "            print(f\"Feature '{feature_name}' is disabled, using fallback\")\n",
        "            return fallback\n",
        "\n",
        "        try:\n",
        "            return operation()\n",
        "        except Exception as e:\n",
        "            if critical:\n",
        "                print(f\"Critical feature '{feature_name}' failed: {e}\")\n",
        "                raise\n",
        "            else:\n",
        "                print(f\"Optional feature '{feature_name}' failed: {e}, using fallback\")\n",
        "                self.features[feature_name] = False  # Disable failing feature\n",
        "                return fallback\n",
        "\n",
        "    def send_analytics(self, event: str):\n",
        "        \"\"\"Send analytics event (optional feature)\"\"\"\n",
        "        def analytics_operation():\n",
        "            # Simulate analytics service that might fail\n",
        "            if random.random() < 0.3:  # 30% failure rate\n",
        "                raise ExternalServiceError(\"analytics_service\", \"send_event\")\n",
        "            return f\"Analytics sent: {event}\"\n",
        "\n",
        "        return self.safe_feature_call(\n",
        "            'analytics',\n",
        "            analytics_operation,\n",
        "            fallback=\"Analytics disabled\",\n",
        "            critical=False\n",
        "        )\n",
        "\n",
        "    def process_payment(self, amount: float):\n",
        "        \"\"\"Process payment (critical feature)\"\"\"\n",
        "        def payment_operation():\n",
        "            if amount <= 0:\n",
        "                raise ValidationError(\"Amount must be positive\")\n",
        "            return f\"Payment of ${amount} processed\"\n",
        "\n",
        "        return self.safe_feature_call(\n",
        "            'payment',\n",
        "            payment_operation,\n",
        "            fallback=None,\n",
        "            critical=True\n",
        "        )\n",
        "\n",
        "# Pattern 6: Error suppression for cleanup\n",
        "class ResourceManager:\n",
        "    \"\"\"Demonstrates safe resource cleanup\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.resources = []\n",
        "\n",
        "    def acquire_resource(self, name: str):\n",
        "        \"\"\"Acquire a resource\"\"\"\n",
        "        print(f\"Acquiring resource: {name}\")\n",
        "        self.resources.append(name)\n",
        "        return name\n",
        "\n",
        "    def release_resource(self, name: str):\n",
        "        \"\"\"Release a resource (might fail)\"\"\"\n",
        "        if \"bad\" in name:\n",
        "            raise Exception(f\"Failed to release {name}\")\n",
        "        print(f\"Released resource: {name}\")\n",
        "        self.resources.remove(name)\n",
        "\n",
        "    def cleanup_all_resources(self):\n",
        "        \"\"\"Clean up all resources, ignoring individual failures\"\"\"\n",
        "        errors = []\n",
        "\n",
        "        for resource in self.resources.copy():\n",
        "            try:\n",
        "                self.release_resource(resource)\n",
        "            except Exception as e:\n",
        "                errors.append(f\"Failed to release {resource}: {e}\")\n",
        "                # Still remove from our list even if release failed\n",
        "                with suppress(ValueError):\n",
        "                    self.resources.remove(resource)\n",
        "\n",
        "        if errors:\n",
        "            print(f\"Cleanup completed with {len(errors)} errors:\")\n",
        "            for error in errors:\n",
        "                print(f\"  - {error}\")\n",
        "        else:\n",
        "            print(\"All resources cleaned up successfully\")\n",
        "\n",
        "        return len(errors) == 0\n",
        "\n",
        "print(\"Advanced error handling patterns defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_G_kQzgFHGS"
      },
      "outputs": [],
      "source": [
        "# Test advanced error handling patterns\n",
        "print(\"=== Advanced Error Handling Demo ===\")\n",
        "\n",
        "# Test graceful degradation\n",
        "print(\"\\n1. Testing graceful degradation:\")\n",
        "feature_manager = FeatureManager()\n",
        "\n",
        "# Send multiple analytics events (some may fail)\n",
        "events = [\"user_login\", \"page_view\", \"button_click\", \"form_submit\", \"user_logout\"]\n",
        "for event in events:\n",
        "    result = feature_manager.send_analytics(event)\n",
        "    print(f\"  {result}\")\n",
        "\n",
        "print(f\"\\nFeature status after tests: {feature_manager.features}\")\n",
        "\n",
        "# Test critical vs non-critical errors\n",
        "print(\"\\n2. Testing critical vs non-critical errors:\")\n",
        "try:\n",
        "    result = feature_manager.process_payment(100.0)\n",
        "    print(f\"  {result}\")\n",
        "except Exception as e:\n",
        "    print(f\"  Critical error caught: {e}\")\n",
        "\n",
        "try:\n",
        "    result = feature_manager.process_payment(-50.0)  # Invalid amount\n",
        "    print(f\"  {result}\")\n",
        "except ValidationError as e:\n",
        "    print(f\"  Validation error caught: {e.message}\")\n",
        "\n",
        "# Test resource cleanup with error suppression\n",
        "print(\"\\n3. Testing resource cleanup:\")\n",
        "resource_manager = ResourceManager()\n",
        "\n",
        "# Acquire some resources\n",
        "resources = [\"database_connection\", \"file_handle\", \"bad_network_connection\", \"cache_connection\"]\n",
        "for resource in resources:\n",
        "    resource_manager.acquire_resource(resource)\n",
        "\n",
        "print(f\"\\nAcquired resources: {resource_manager.resources}\")\n",
        "\n",
        "# Clean up all resources\n",
        "print(\"\\nCleaning up resources:\")\n",
        "success = resource_manager.cleanup_all_resources()\n",
        "print(f\"Cleanup successful: {success}\")\n",
        "print(f\"Remaining resources: {resource_manager.resources}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZAxbAr4FHGT"
      },
      "source": [
        "## 2. Logging Best Practices\n",
        "\n",
        "Effective logging provides visibility into application behavior, aids debugging, and supports monitoring and alerting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ki1mHXxFHGT"
      },
      "outputs": [],
      "source": [
        "# Comprehensive logging setup and patterns\n",
        "import logging\n",
        "import logging.handlers\n",
        "import sys\n",
        "import json\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from typing import Any, Dict, Optional\n",
        "import threading\n",
        "import functools\n",
        "\n",
        "# Custom JSON formatter for structured logging\n",
        "class JSONFormatter(logging.Formatter):\n",
        "    \"\"\"Custom formatter to output logs in JSON format\"\"\"\n",
        "\n",
        "    def format(self, record):\n",
        "        log_entry = {\n",
        "            'timestamp': datetime.fromtimestamp(record.created).isoformat(),\n",
        "            'level': record.levelname,\n",
        "            'logger': record.name,\n",
        "            'message': record.getMessage(),\n",
        "            'module': record.module,\n",
        "            'function': record.funcName,\n",
        "            'line': record.lineno,\n",
        "        }\n",
        "\n",
        "        # Add process and thread info\n",
        "        log_entry['process_id'] = record.process\n",
        "        log_entry['thread_id'] = record.thread\n",
        "\n",
        "        # Add exception info if present\n",
        "        if record.exc_info:\n",
        "            log_entry['exception'] = self.formatException(record.exc_info)\n",
        "\n",
        "        # Add extra fields\n",
        "        for key, value in record.__dict__.items():\n",
        "            if key not in ['name', 'msg', 'args', 'levelname', 'levelno', 'pathname',\n",
        "                          'filename', 'module', 'exc_info', 'exc_text', 'stack_info',\n",
        "                          'lineno', 'funcName', 'created', 'msecs', 'relativeCreated',\n",
        "                          'thread', 'threadName', 'processName', 'process', 'getMessage']:\n",
        "                log_entry[key] = value\n",
        "\n",
        "        return json.dumps(log_entry, default=str)\n",
        "\n",
        "# Context manager for request/operation tracking\n",
        "class LoggingContext:\n",
        "    \"\"\"Context manager for adding context to all logs within a scope\"\"\"\n",
        "\n",
        "    _context = threading.local()\n",
        "\n",
        "    def __init__(self, **context):\n",
        "        self.context = context\n",
        "        self.previous_context = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.previous_context = getattr(self._context, 'data', {})\n",
        "        new_context = self.previous_context.copy()\n",
        "        new_context.update(self.context)\n",
        "        self._context.data = new_context\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self._context.data = self.previous_context\n",
        "\n",
        "    @classmethod\n",
        "    def get_context(cls) -> Dict[str, Any]:\n",
        "        return getattr(cls._context, 'data', {})\n",
        "\n",
        "# Custom log filter to add context\n",
        "class ContextFilter(logging.Filter):\n",
        "    \"\"\"Filter that adds context information to log records\"\"\"\n",
        "\n",
        "    def filter(self, record):\n",
        "        context = LoggingContext.get_context()\n",
        "        for key, value in context.items():\n",
        "            setattr(record, key, value)\n",
        "        return True\n",
        "\n",
        "# Logging configuration manager\n",
        "class LoggingManager:\n",
        "    \"\"\"Centralized logging configuration and management\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loggers = {}\n",
        "\n",
        "    def setup_logging(self,\n",
        "                     level: str = 'INFO',\n",
        "                     console_output: bool = True,\n",
        "                     file_output: Optional[str] = None,\n",
        "                     json_format: bool = False,\n",
        "                     max_file_size: int = 10 * 1024 * 1024,  # 10MB\n",
        "                     backup_count: int = 5):\n",
        "        \"\"\"Set up logging configuration\"\"\"\n",
        "\n",
        "        # Clear existing handlers\n",
        "        root_logger = logging.getLogger()\n",
        "        root_logger.handlers.clear()\n",
        "\n",
        "        # Set level\n",
        "        root_logger.setLevel(getattr(logging, level.upper()))\n",
        "\n",
        "        # Create formatter\n",
        "        if json_format:\n",
        "            formatter = JSONFormatter()\n",
        "        else:\n",
        "            formatter = logging.Formatter(\n",
        "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "            )\n",
        "\n",
        "        # Console handler\n",
        "        if console_output:\n",
        "            console_handler = logging.StreamHandler(sys.stdout)\n",
        "            console_handler.setFormatter(formatter)\n",
        "            console_handler.addFilter(ContextFilter())\n",
        "            root_logger.addHandler(console_handler)\n",
        "\n",
        "        # File handler with rotation\n",
        "        if file_output:\n",
        "            file_handler = logging.handlers.RotatingFileHandler(\n",
        "                file_output,\n",
        "                maxBytes=max_file_size,\n",
        "                backupCount=backup_count\n",
        "            )\n",
        "            file_handler.setFormatter(formatter)\n",
        "            file_handler.addFilter(ContextFilter())\n",
        "            root_logger.addHandler(file_handler)\n",
        "\n",
        "    def get_logger(self, name: str) -> logging.Logger:\n",
        "        \"\"\"Get a logger instance\"\"\"\n",
        "        if name not in self.loggers:\n",
        "            self.loggers[name] = logging.getLogger(name)\n",
        "        return self.loggers[name]\n",
        "\n",
        "    def set_logger_level(self, logger_name: str, level: str):\n",
        "        \"\"\"Set specific logger level\"\"\"\n",
        "        logger = self.get_logger(logger_name)\n",
        "        logger.setLevel(getattr(logging, level.upper()))\n",
        "\n",
        "# Initialize logging manager\n",
        "logging_manager = LoggingManager()\n",
        "logging_manager.setup_logging(level='DEBUG', json_format=False)\n",
        "\n",
        "print(\"Logging framework configured.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdnDemTmFHGT"
      },
      "outputs": [],
      "source": [
        "# Logging patterns and decorators\n",
        "import time\n",
        "import inspect\n",
        "from functools import wraps\n",
        "\n",
        "# Decorator for automatic logging of function calls\n",
        "def log_function_calls(level: str = 'DEBUG', include_args: bool = True, include_result: bool = True):\n",
        "    \"\"\"Decorator to automatically log function calls\"\"\"\n",
        "    def decorator(func):\n",
        "        logger = logging_manager.get_logger(func.__module__)\n",
        "        log_level = getattr(logging, level.upper())\n",
        "\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            func_name = func.__name__\n",
        "\n",
        "            # Log function entry\n",
        "            if include_args:\n",
        "                # Get argument names\n",
        "                sig = inspect.signature(func)\n",
        "                bound_args = sig.bind(*args, **kwargs)\n",
        "                bound_args.apply_defaults()\n",
        "                args_str = ', '.join(f'{k}={v}' for k, v in bound_args.arguments.items())\n",
        "                logger.log(log_level, f\"Calling {func_name}({args_str})\")\n",
        "            else:\n",
        "                logger.log(log_level, f\"Calling {func_name}\")\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "                execution_time = time.time() - start_time\n",
        "\n",
        "                # Log successful completion\n",
        "                if include_result:\n",
        "                    logger.log(log_level,\n",
        "                             f\"{func_name} completed in {execution_time:.3f}s, result: {result}\")\n",
        "                else:\n",
        "                    logger.log(log_level,\n",
        "                             f\"{func_name} completed in {execution_time:.3f}s\")\n",
        "\n",
        "                return result\n",
        "\n",
        "            except Exception as e:\n",
        "                execution_time = time.time() - start_time\n",
        "                logger.error(f\"{func_name} failed after {execution_time:.3f}s: {e}\", exc_info=True)\n",
        "                raise\n",
        "\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Performance logging decorator\n",
        "def log_performance(threshold_ms: float = 100.0):\n",
        "    \"\"\"Log performance metrics for slow operations\"\"\"\n",
        "    def decorator(func):\n",
        "        logger = logging_manager.get_logger(f\"{func.__module__}.performance\")\n",
        "\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            start_time = time.time()\n",
        "            result = func(*args, **kwargs)\n",
        "            execution_time = (time.time() - start_time) * 1000  # Convert to ms\n",
        "\n",
        "            if execution_time > threshold_ms:\n",
        "                logger.warning(\n",
        "                    f\"Slow operation detected: {func.__name__} took {execution_time:.2f}ms\",\n",
        "                    extra={\n",
        "                        'function': func.__name__,\n",
        "                        'execution_time_ms': execution_time,\n",
        "                        'threshold_ms': threshold_ms\n",
        "                    }\n",
        "                )\n",
        "            else:\n",
        "                logger.debug(\n",
        "                    f\"Performance: {func.__name__} took {execution_time:.2f}ms\",\n",
        "                    extra={\n",
        "                        'function': func.__name__,\n",
        "                        'execution_time_ms': execution_time\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            return result\n",
        "\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Business logic with logging\n",
        "class UserService:\n",
        "    \"\"\"User service with comprehensive logging\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.logger = logging_manager.get_logger(f\"{__name__}.UserService\")\n",
        "        self.users = {\n",
        "            1: {'id': 1, 'name': 'Alice', 'email': 'alice@example.com', 'active': True},\n",
        "            2: {'id': 2, 'name': 'Bob', 'email': 'bob@example.com', 'active': True},\n",
        "            3: {'id': 3, 'name': 'Charlie', 'email': 'charlie@example.com', 'active': False},\n",
        "        }\n",
        "\n",
        "    @log_function_calls(level='INFO', include_args=True)\n",
        "    def get_user(self, user_id: int) -> Dict[str, Any]:\n",
        "        \"\"\"Get user by ID with logging\"\"\"\n",
        "        self.logger.debug(f\"Looking up user with ID: {user_id}\")\n",
        "\n",
        "        if user_id not in self.users:\n",
        "            self.logger.warning(f\"User not found: {user_id}\")\n",
        "            raise ResourceNotFoundError(\"User\", user_id)\n",
        "\n",
        "        user = self.users[user_id]\n",
        "        self.logger.info(f\"Successfully retrieved user: {user['name']}\")\n",
        "        return user\n",
        "\n",
        "    @log_function_calls(level='INFO')\n",
        "    @log_performance(threshold_ms=50)\n",
        "    def search_users(self, query: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Search users by name or email\"\"\"\n",
        "        self.logger.info(f\"Searching users with query: '{query}'\")\n",
        "\n",
        "        # Simulate some processing time\n",
        "        time.sleep(0.1)  # 100ms delay to trigger performance warning\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        results = []\n",
        "\n",
        "        for user in self.users.values():\n",
        "            if (query_lower in user['name'].lower() or\n",
        "                query_lower in user['email'].lower()):\n",
        "                results.append(user)\n",
        "\n",
        "        self.logger.info(f\"Search returned {len(results)} results\")\n",
        "        return results\n",
        "\n",
        "    @log_function_calls(level='INFO')\n",
        "    def update_user_status(self, user_id: int, active: bool) -> bool:\n",
        "        \"\"\"Update user active status\"\"\"\n",
        "        try:\n",
        "            user = self.get_user(user_id)  # This will log the lookup\n",
        "            old_status = user['active']\n",
        "            user['active'] = active\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Updated user {user_id} status from {old_status} to {active}\",\n",
        "                extra={\n",
        "                    'user_id': user_id,\n",
        "                    'old_status': old_status,\n",
        "                    'new_status': active,\n",
        "                    'operation': 'status_update'\n",
        "                }\n",
        "            )\n",
        "            return True\n",
        "\n",
        "        except ResourceNotFoundError as e:\n",
        "            self.logger.error(f\"Failed to update user status: {e.message}\")\n",
        "            raise\n",
        "\n",
        "    def process_bulk_operation(self, user_ids: List[int], operation: str):\n",
        "        \"\"\"Process bulk operation with detailed logging\"\"\"\n",
        "        operation_id = str(uuid.uuid4())[:8]\n",
        "\n",
        "        with LoggingContext(operation_id=operation_id, operation_type=operation):\n",
        "            self.logger.info(f\"Starting bulk operation: {operation} on {len(user_ids)} users\")\n",
        "\n",
        "            successful = 0\n",
        "            failed = 0\n",
        "\n",
        "            for user_id in user_ids:\n",
        "                with LoggingContext(current_user_id=user_id):\n",
        "                    try:\n",
        "                        if operation == 'deactivate':\n",
        "                            self.update_user_status(user_id, False)\n",
        "                        elif operation == 'activate':\n",
        "                            self.update_user_status(user_id, True)\n",
        "                        else:\n",
        "                            raise ValidationError(f\"Unknown operation: {operation}\")\n",
        "\n",
        "                        successful += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        failed += 1\n",
        "                        self.logger.error(f\"Failed to process user {user_id}: {e}\")\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Bulk operation completed: {successful} successful, {failed} failed\",\n",
        "                extra={\n",
        "                    'successful_count': successful,\n",
        "                    'failed_count': failed,\n",
        "                    'total_count': len(user_ids)\n",
        "                }\n",
        "            )\n",
        "\n",
        "print(\"Logging patterns and decorators defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHWNJfD5FHGT"
      },
      "outputs": [],
      "source": [
        "# Demonstrate logging patterns\n",
        "print(\"=== Logging Patterns Demo ===\")\n",
        "\n",
        "user_service = UserService()\n",
        "\n",
        "print(\"\\n1. Basic operations with automatic logging:\")\n",
        "\n",
        "# Test successful operations\n",
        "try:\n",
        "    user = user_service.get_user(1)\n",
        "    print(f\"Retrieved user: {user['name']}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "# Test error case\n",
        "try:\n",
        "    user = user_service.get_user(999)\n",
        "except ResourceNotFoundError as e:\n",
        "    print(f\"Expected error: {e.message}\")\n",
        "\n",
        "print(\"\\n2. Performance logging:\")\n",
        "results = user_service.search_users(\"alice\")\n",
        "print(f\"Search results: {len(results)} users found\")\n",
        "\n",
        "print(\"\\n3. Context-aware logging (bulk operations):\")\n",
        "user_service.process_bulk_operation([1, 2, 999, 3], 'deactivate')\n",
        "\n",
        "print(\"\\n4. Different log levels:\")\n",
        "logger = logging_manager.get_logger(\"demo\")\n",
        "\n",
        "logger.debug(\"This is a debug message\")\n",
        "logger.info(\"This is an info message\")\n",
        "logger.warning(\"This is a warning message\")\n",
        "logger.error(\"This is an error message\")\n",
        "\n",
        "# Log with extra context\n",
        "logger.info(\n",
        "    \"User action performed\",\n",
        "    extra={\n",
        "        'user_id': 123,\n",
        "        'action': 'profile_update',\n",
        "        'ip_address': '192.168.1.100',\n",
        "        'user_agent': 'Mozilla/5.0...'\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"\\n5. Exception logging:\")\n",
        "try:\n",
        "    # Cause an exception to demonstrate exception logging\n",
        "    result = 1 / 0\n",
        "except ZeroDivisionError as e:\n",
        "    logger.exception(\"Mathematical error occurred\")\n",
        "    print(\"Exception logged with full traceback\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBIdZ7XZFHGT"
      },
      "outputs": [],
      "source": [
        "# Demonstrate structured logging with JSON format\n",
        "print(\"\\n=== Structured Logging Demo ===\")\n",
        "\n",
        "# Reconfigure logging for JSON output\n",
        "logging_manager.setup_logging(level='INFO', json_format=True)\n",
        "\n",
        "# Create a new logger for structured logging demo\n",
        "structured_logger = logging_manager.get_logger(\"structured_demo\")\n",
        "\n",
        "print(\"\\nJSON formatted logs:\")\n",
        "\n",
        "# Log with context\n",
        "with LoggingContext(request_id=\"req_123\", user_id=\"user_456\"):\n",
        "    structured_logger.info(\"Processing user request\")\n",
        "\n",
        "    with LoggingContext(step=\"validation\"):\n",
        "        structured_logger.debug(\"Validating input parameters\")\n",
        "        structured_logger.info(\"Validation completed successfully\")\n",
        "\n",
        "    with LoggingContext(step=\"business_logic\"):\n",
        "        structured_logger.info(\"Executing business logic\")\n",
        "\n",
        "        # Simulate an error\n",
        "        try:\n",
        "            raise BusinessLogicError(\"Insufficient balance\", rule=\"minimum_balance\")\n",
        "        except BusinessLogicError as e:\n",
        "            structured_logger.error(\n",
        "                \"Business rule violation\",\n",
        "                extra={\n",
        "                    'error_code': e.error_code,\n",
        "                    'rule': e.rule,\n",
        "                    'balance': 50.0,\n",
        "                    'required': 100.0\n",
        "                }\n",
        "            )\n",
        "\n",
        "# Log metrics\n",
        "structured_logger.info(\n",
        "    \"Request completed\",\n",
        "    extra={\n",
        "        'duration_ms': 234.5,\n",
        "        'status_code': 400,\n",
        "        'bytes_sent': 1024,\n",
        "        'cache_hit': False\n",
        "    }\n",
        ")\n",
        "\n",
        "# Reset to regular logging for remaining demos\n",
        "logging_manager.setup_logging(level='INFO', json_format=False)\n",
        "print(\"\\n(Logging format reset to regular text)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E16lGMJ6FHGU"
      },
      "outputs": [],
      "source": [
        "# Advanced logging patterns\n",
        "print(\"\\n=== Advanced Logging Patterns ===\")\n",
        "\n",
        "# Rate-limited logging to prevent log spam\n",
        "class RateLimitedLogger:\n",
        "    \"\"\"Logger that rate-limits repeated messages\"\"\"\n",
        "\n",
        "    def __init__(self, logger: logging.Logger, max_messages: int = 5, window_seconds: int = 60):\n",
        "        self.logger = logger\n",
        "        self.max_messages = max_messages\n",
        "        self.window_seconds = window_seconds\n",
        "        self.message_counts = {}\n",
        "        self.last_reset = time.time()\n",
        "\n",
        "    def _reset_if_needed(self):\n",
        "        current_time = time.time()\n",
        "        if current_time - self.last_reset > self.window_seconds:\n",
        "            self.message_counts.clear()\n",
        "            self.last_reset = current_time\n",
        "\n",
        "    def log(self, level: int, message: str, *args, **kwargs):\n",
        "        \"\"\"Log message with rate limiting\"\"\"\n",
        "        self._reset_if_needed()\n",
        "\n",
        "        # Use message template as key for rate limiting\n",
        "        message_key = message % args if args else message\n",
        "\n",
        "        count = self.message_counts.get(message_key, 0)\n",
        "\n",
        "        if count < self.max_messages:\n",
        "            self.logger.log(level, message, *args, **kwargs)\n",
        "            self.message_counts[message_key] = count + 1\n",
        "        elif count == self.max_messages:\n",
        "            self.logger.log(\n",
        "                level,\n",
        "                f\"Rate limit reached for message: '{message_key}'. Suppressing further occurrences.\",\n",
        "                **kwargs\n",
        "            )\n",
        "            self.message_counts[message_key] = count + 1\n",
        "\n",
        "    def info(self, message: str, *args, **kwargs):\n",
        "        self.log(logging.INFO, message, *args, **kwargs)\n",
        "\n",
        "    def warning(self, message: str, *args, **kwargs):\n",
        "        self.log(logging.WARNING, message, *args, **kwargs)\n",
        "\n",
        "    def error(self, message: str, *args, **kwargs):\n",
        "        self.log(logging.ERROR, message, *args, **kwargs)\n",
        "\n",
        "# Sampling logger for high-frequency events\n",
        "class SamplingLogger:\n",
        "    \"\"\"Logger that samples high-frequency events\"\"\"\n",
        "\n",
        "    def __init__(self, logger: logging.Logger, sample_rate: float = 0.1):\n",
        "        self.logger = logger\n",
        "        self.sample_rate = sample_rate\n",
        "        self.total_events = 0\n",
        "        self.logged_events = 0\n",
        "\n",
        "    def log_event(self, level: int, message: str, *args, **kwargs):\n",
        "        \"\"\"Log event with sampling\"\"\"\n",
        "        self.total_events += 1\n",
        "\n",
        "        if random.random() < self.sample_rate:\n",
        "            # Add sampling info to the log\n",
        "            extra = kwargs.get('extra', {})\n",
        "            extra.update({\n",
        "                'sampled': True,\n",
        "                'sample_rate': self.sample_rate,\n",
        "                'total_events': self.total_events\n",
        "            })\n",
        "            kwargs['extra'] = extra\n",
        "\n",
        "            self.logger.log(level, message, *args, **kwargs)\n",
        "            self.logged_events += 1\n",
        "\n",
        "    def get_stats(self):\n",
        "        return {\n",
        "            'total_events': self.total_events,\n",
        "            'logged_events': self.logged_events,\n",
        "            'sample_rate': self.sample_rate\n",
        "        }\n",
        "\n",
        "# Test rate-limited logging\n",
        "print(\"\\n1. Rate-limited logging demo:\")\n",
        "base_logger = logging_manager.get_logger(\"rate_limited_demo\")\n",
        "rate_limited_logger = RateLimitedLogger(base_logger, max_messages=3, window_seconds=60)\n",
        "\n",
        "# Simulate repeated error messages\n",
        "for i in range(8):\n",
        "    rate_limited_logger.error(\"Database connection failed: attempt %d\", i)\n",
        "\n",
        "# Test sampling logger\n",
        "print(\"\\n2. Sampling logger demo:\")\n",
        "sampling_logger = SamplingLogger(\n",
        "    logging_manager.get_logger(\"sampling_demo\"),\n",
        "    sample_rate=0.3  # Log 30% of events\n",
        ")\n",
        "\n",
        "# Simulate high-frequency events\n",
        "for i in range(20):\n",
        "    sampling_logger.log_event(\n",
        "        logging.INFO,\n",
        "        \"High frequency event: %d\",\n",
        "        i,\n",
        "        extra={'event_type': 'page_view', 'user_id': f'user_{i % 5}'}\n",
        "    )\n",
        "\n",
        "stats = sampling_logger.get_stats()\n",
        "print(f\"\\nSampling stats: {stats}\")\n",
        "\n",
        "# Security-aware logging\n",
        "print(\"\\n3. Security-aware logging:\")\n",
        "security_logger = logging_manager.get_logger(\"security\")\n",
        "\n",
        "def safe_log_user_data(user_data: Dict[str, Any]):\n",
        "    \"\"\"Log user data while masking sensitive information\"\"\"\n",
        "    # Fields to mask completely\n",
        "    sensitive_fields = {'password', 'ssn', 'credit_card'}\n",
        "    # Fields to partially mask\n",
        "    partial_mask_fields = {'email', 'phone'}\n",
        "\n",
        "    safe_data = {}\n",
        "\n",
        "    for key, value in user_data.items():\n",
        "        if key.lower() in sensitive_fields:\n",
        "            safe_data[key] = '[REDACTED]'\n",
        "        elif key.lower() in partial_mask_fields and isinstance(value, str):\n",
        "            if '@' in value:  # Email\n",
        "                parts = value.split('@')\n",
        "                safe_data[key] = f\"{parts[0][:2]}***@{parts[1]}\"\n",
        "            else:  # Phone or other\n",
        "                safe_data[key] = f\"{value[:3]}***{value[-2:]}\" if len(value) > 5 else '[MASKED]'\n",
        "        else:\n",
        "            safe_data[key] = value\n",
        "\n",
        "    security_logger.info(\"User data logged\", extra={'user_data': safe_data})\n",
        "\n",
        "# Test security logging\n",
        "test_user_data = {\n",
        "    'id': 123,\n",
        "    'name': 'John Doe',\n",
        "    'email': 'john.doe@example.com',\n",
        "    'phone': '555-123-4567',\n",
        "    'password': 'secret123',\n",
        "    'ssn': '123-45-6789'\n",
        "}\n",
        "\n",
        "safe_log_user_data(test_user_data)\n",
        "\n",
        "print(\"\\nAdvanced logging patterns demonstrated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51VGJQ-qFHGU"
      },
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Custom Exceptions**: Create specific exception types for clear error communication and handling\n",
        "2. **Exception Chaining**: Preserve context when re-raising exceptions using `raise X from Y`\n",
        "3. **Graceful Degradation**: Handle non-critical failures gracefully while maintaining core functionality\n",
        "4. **Structured Logging**: Use consistent formats and include contextual information for better debugging\n",
        "5. **Performance Logging**: Monitor slow operations and set appropriate thresholds\n",
        "6. **Security Awareness**: Never log sensitive information; mask or redact as needed\n",
        "\n",
        "## Best Practices\n",
        "\n",
        "### Exception Handling\n",
        "- Use specific exception types rather than catching broad `Exception`\n",
        "- Implement retry logic for transient failures\n",
        "- Always clean up resources using context managers or try/finally\n",
        "- Log exceptions with sufficient context for debugging\n",
        "- Consider the call stack when deciding where to handle exceptions\n",
        "\n",
        "### Logging\n",
        "- Configure logging early in application startup\n",
        "- Use appropriate log levels (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
        "- Include contextual information in log messages\n",
        "- Use structured logging for better searchability\n",
        "- Implement log rotation to prevent disk space issues\n",
        "- Be mindful of performance impact in high-frequency code paths\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Create a custom exception hierarchy for a banking application\n",
        "2. Implement a retry decorator with exponential backoff for API calls\n",
        "3. Build a logging configuration that outputs to both console and rotating files\n",
        "4. Create a context manager for database transactions with proper error handling\n",
        "5. Implement a sampling logger for high-frequency events\n",
        "6. Design a security-aware logger that automatically masks sensitive data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}